# Project - CPSC 8570: Network Technologies Security
### Inspired by Google DeepMind - Informed Adversary MNIST Reconstruction

This repository contains a minimal implementation of a training data reconstruction attack with an informed adversary on the MNIST dataset, as described in the paper by B. Balle, G. Cherubin, and J. Hayes at the 2022 IEEE Symposium on Security and Privacy (SP).

The attack aims to reconstruct training data examples using information about the model's predictions, posing a threat to the privacy of sensitive data used for training machine learning models.

For more details, please refer to the original paper: [Reconstructing Training Data with Informed Adversaries](https://arxiv.org/abs/2201.04845) by B. Balle, G. Cherubin, and J. Hayes.

### Usage
- Clone the repository
- Follow the instructions in the `Jupyter Notebook` file to run the implementation

Feel free to contribute or raise issues if you encounter any problems or have suggestions for improvements.
